{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DenseNet121_Example.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"7c762c46dfb541a3acc63ce1f8c9c223":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a85bccefc35b4dc8ae5cb0bd94d56db1","IPY_MODEL_64761e12680845c596802a1af6e606a4","IPY_MODEL_e217c33f914347fc87c2633f7dc296df"],"layout":"IPY_MODEL_16cd4e6cd1a848f7b0dc2ecfe791be07"}},"a85bccefc35b4dc8ae5cb0bd94d56db1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b941ff264ab465b9de28eb403b1e8d9","placeholder":"​","style":"IPY_MODEL_c1d2bf7dd78f4b2b92bf88c96def5725","value":"100%"}},"64761e12680845c596802a1af6e606a4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_30184e023a3745ae9acdcd6ea9f4d546","max":32342954,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d950cf14e4f049ccb95d7b203fe9e812","value":32342954}},"e217c33f914347fc87c2633f7dc296df":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_515522cbc04e42dc914da9cf971cd242","placeholder":"​","style":"IPY_MODEL_13aaebc0ef214ca7b1082bcc556dcedd","value":" 30.8M/30.8M [00:00&lt;00:00, 146MB/s]"}},"16cd4e6cd1a848f7b0dc2ecfe791be07":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b941ff264ab465b9de28eb403b1e8d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1d2bf7dd78f4b2b92bf88c96def5725":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"30184e023a3745ae9acdcd6ea9f4d546":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d950cf14e4f049ccb95d7b203fe9e812":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"515522cbc04e42dc914da9cf971cd242":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13aaebc0ef214ca7b1082bcc556dcedd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"UaBjlUzrX5tT"},"outputs":[],"source":["import torch"]},{"cell_type":"markdown","source":["* DenseNet121: https://pytorch.org/hub/pytorch_vision_densenet/"],"metadata":{"id":"wg7DwuQVYK7V"}},{"cell_type":"code","source":["model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet121', pretrained=True)\n","# or any of these variants\n","# model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet169', pretrained=True)\n","# model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet201', pretrained=True)\n","# model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet161', pretrained=True)\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["7c762c46dfb541a3acc63ce1f8c9c223","a85bccefc35b4dc8ae5cb0bd94d56db1","64761e12680845c596802a1af6e606a4","e217c33f914347fc87c2633f7dc296df","16cd4e6cd1a848f7b0dc2ecfe791be07","4b941ff264ab465b9de28eb403b1e8d9","c1d2bf7dd78f4b2b92bf88c96def5725","30184e023a3745ae9acdcd6ea9f4d546","d950cf14e4f049ccb95d7b203fe9e812","515522cbc04e42dc914da9cf971cd242","13aaebc0ef214ca7b1082bcc556dcedd"]},"id":"cgiTFSFOX9r0","executionInfo":{"status":"ok","timestamp":1649273862048,"user_tz":240,"elapsed":2894,"user":{"displayName":"Nancy Li","userId":"12562624317552008542"}},"outputId":"2026b3a7-353b-46cf-bff3-34331702278a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/pytorch/vision/archive/v0.10.0.zip\" to /root/.cache/torch/hub/v0.10.0.zip\n","Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/30.8M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c762c46dfb541a3acc63ce1f8c9c223"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["DenseNet(\n","  (features): Sequential(\n","    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu0): ReLU(inplace=True)\n","    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (denseblock1): _DenseBlock(\n","      (denselayer1): _DenseLayer(\n","        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer2): _DenseLayer(\n","        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer3): _DenseLayer(\n","        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer4): _DenseLayer(\n","        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer5): _DenseLayer(\n","        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer6): _DenseLayer(\n","        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","    )\n","    (transition1): _Transition(\n","      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    )\n","    (denseblock2): _DenseBlock(\n","      (denselayer1): _DenseLayer(\n","        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer2): _DenseLayer(\n","        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer3): _DenseLayer(\n","        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer4): _DenseLayer(\n","        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer5): _DenseLayer(\n","        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer6): _DenseLayer(\n","        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer7): _DenseLayer(\n","        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer8): _DenseLayer(\n","        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer9): _DenseLayer(\n","        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer10): _DenseLayer(\n","        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer11): _DenseLayer(\n","        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer12): _DenseLayer(\n","        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","    )\n","    (transition2): _Transition(\n","      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    )\n","    (denseblock3): _DenseBlock(\n","      (denselayer1): _DenseLayer(\n","        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer2): _DenseLayer(\n","        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer3): _DenseLayer(\n","        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer4): _DenseLayer(\n","        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer5): _DenseLayer(\n","        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer6): _DenseLayer(\n","        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer7): _DenseLayer(\n","        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer8): _DenseLayer(\n","        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer9): _DenseLayer(\n","        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer10): _DenseLayer(\n","        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer11): _DenseLayer(\n","        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer12): _DenseLayer(\n","        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer13): _DenseLayer(\n","        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer14): _DenseLayer(\n","        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer15): _DenseLayer(\n","        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer16): _DenseLayer(\n","        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer17): _DenseLayer(\n","        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer18): _DenseLayer(\n","        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer19): _DenseLayer(\n","        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer20): _DenseLayer(\n","        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer21): _DenseLayer(\n","        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer22): _DenseLayer(\n","        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer23): _DenseLayer(\n","        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer24): _DenseLayer(\n","        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","    )\n","    (transition3): _Transition(\n","      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    )\n","    (denseblock4): _DenseBlock(\n","      (denselayer1): _DenseLayer(\n","        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer2): _DenseLayer(\n","        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer3): _DenseLayer(\n","        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer4): _DenseLayer(\n","        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer5): _DenseLayer(\n","        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer6): _DenseLayer(\n","        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer7): _DenseLayer(\n","        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer8): _DenseLayer(\n","        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer9): _DenseLayer(\n","        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer10): _DenseLayer(\n","        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer11): _DenseLayer(\n","        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer12): _DenseLayer(\n","        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer13): _DenseLayer(\n","        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer14): _DenseLayer(\n","        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer15): _DenseLayer(\n","        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer16): _DenseLayer(\n","        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","    )\n","    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (classifier): Linear(in_features=1024, out_features=1000, bias=True)\n",")"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["import urllib\n","url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n","try: urllib.URLopener().retrieve(url, filename)\n","except: urllib.request.urlretrieve(url, filename)"],"metadata":{"id":"W0kISctlYSuu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# sample execution (requires torchvision)\n","from PIL import Image\n","from torchvision import transforms\n","input_image = Image.open(filename)\n","preprocess = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","input_tensor = preprocess(input_image)\n","input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n","\n","# move the input and model to GPU for speed if available\n","if torch.cuda.is_available():\n","    input_batch = input_batch.to('cuda')\n","    model.to('cuda')\n","\n","with torch.no_grad():\n","    output = model(input_batch)\n","# Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n","print(output[0])\n","# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n","probabilities = torch.nn.functional.softmax(output[0], dim=0)\n","print(probabilities)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"po_pRKZqYSmx","executionInfo":{"status":"ok","timestamp":1649273865711,"user_tz":240,"elapsed":545,"user":{"displayName":"Nancy Li","userId":"12562624317552008542"}},"outputId":"cc9ec6d4-45a5-4492-f42a-fe211456555b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([ 1.1006e+00, -1.6553e+00, -2.4894e+00, -3.2315e+00, -1.2697e+00,\n","        -4.8822e-02,  1.2791e-01,  2.3051e+00,  4.3685e+00,  9.2677e-01,\n","        -2.6016e+00, -1.8257e+00, -3.0931e+00, -1.7628e+00, -4.4180e-01,\n","        -2.6964e+00, -1.9900e+00,  1.4200e+00,  1.6947e-01, -1.9450e+00,\n","        -1.9205e+00,  4.4206e-01, -5.8945e-01,  1.4815e+00, -8.9452e-01,\n","        -5.2757e-01, -8.6152e-01,  4.0436e-01, -4.0194e-01,  2.4117e+00,\n","        -2.6380e+00, -1.5081e-01, -6.6622e-01, -3.5953e+00, -3.2856e+00,\n","        -2.6778e+00, -1.8680e+00, -2.5294e+00, -9.2201e-01, -2.1237e+00,\n","        -5.8481e-01, -1.9349e+00, -3.4944e+00, -2.2803e+00, -4.3990e-01,\n","        -2.8090e+00,  4.4738e-01, -7.7097e-01, -1.9056e+00,  8.7831e-02,\n","         5.4203e-01, -1.1273e+00,  1.0430e-01, -2.2836e+00, -1.9692e+00,\n","        -2.0732e+00, -6.8284e-01, -2.5332e+00, -1.5760e+00, -6.6341e-01,\n","         1.7951e-01, -1.7511e+00, -7.2102e-01, -2.7178e+00, -1.5430e+00,\n","        -2.7509e+00, -1.8886e+00, -1.8676e+00, -7.6483e-01, -3.4762e+00,\n","        -2.3765e+00, -6.2552e-01, -1.1100e+00, -1.2186e+00, -2.5414e+00,\n","        -1.7461e-01, -8.5426e-01, -7.0968e-01,  1.3231e+00,  6.0526e-01,\n","         5.7655e-02,  2.1794e+00, -4.2915e-01, -7.3574e-01,  7.5784e-01,\n","        -1.3094e+00, -8.4353e-01, -1.6118e+00, -1.9288e+00,  3.5002e+00,\n","        -1.5336e+00, -2.6986e+00, -4.2995e+00, -1.3716e+00, -2.3188e+00,\n","        -3.5077e+00, -1.9151e+00, -3.5740e+00, -4.8803e+00, -2.1889e-01,\n","        -1.0644e+00, -3.7925e+00, -5.2142e-01, -2.9136e+00,  7.1519e+00,\n","        -6.0861e-01,  1.9468e+00, -3.6803e+00, -1.9403e+00, -2.9075e+00,\n","        -1.2664e+00, -2.6804e+00, -1.3483e+00, -1.0111e+00, -9.3249e-01,\n","        -5.7798e-01, -3.8511e+00, -2.6792e+00, -1.0200e+00, -1.3497e+00,\n","        -3.4234e+00, -9.5525e-01, -9.1635e-01, -1.5191e+00, -1.2113e+00,\n","        -3.2584e+00, -2.7060e-01,  7.5439e-01, -2.5098e+00,  6.2337e-01,\n","        -1.4190e+00, -1.4789e+00,  9.2091e-01, -5.6673e+00, -1.5491e-01,\n","        -1.7341e+00, -2.7179e+00, -3.9126e+00, -2.9955e+00, -3.3346e+00,\n","        -3.3065e+00, -3.7190e+00, -3.3106e+00, -1.1109e+00, -7.7622e-01,\n","        -9.1878e-02,  2.7579e-01, -2.9323e+00, -3.8603e+00, -9.8156e-01,\n","        -2.8368e+00,  4.3802e+00,  5.7550e+00,  4.3740e+00,  6.4430e+00,\n","        -9.5171e-01,  1.6249e-01,  5.5196e+00,  1.2657e+00, -6.7396e-01,\n","         1.8719e+00, -1.5205e+00, -1.5668e+00,  3.4610e-01, -2.0612e+00,\n","        -2.2598e+00, -4.3264e-01, -1.8631e+00,  1.4353e+00,  4.8591e+00,\n","         2.6641e+00, -7.9527e-01, -2.6301e+00,  9.0192e-01,  6.5981e+00,\n","         1.3371e+00, -2.0086e+00,  2.4646e+00, -2.0196e+00,  2.2070e+00,\n","         6.9907e-01, -1.3463e+00,  1.1367e+00, -1.3450e+00,  1.6727e+00,\n","         3.5785e+00,  3.1145e+00, -1.1559e+00,  1.8016e+00, -1.7649e+00,\n","         5.9190e-01, -2.3269e+00,  3.9688e+00,  3.2913e+00, -8.6019e-02,\n","         9.4517e-01, -2.7814e+00, -1.0898e+00, -2.2131e+00,  3.7984e+00,\n","         9.8704e-01,  7.2347e-01,  1.0618e+00,  6.8043e+00,  1.1646e+00,\n","         1.0329e+00, -4.2965e-01,  4.4828e+00,  2.5275e+00, -3.7767e-02,\n","        -1.2838e+00,  6.1254e-01,  2.7527e+00,  1.0574e+00,  3.6797e-02,\n","         1.4410e+00,  2.5108e+00, -4.2498e-01, -7.0483e-02, -2.5585e-01,\n","         8.8975e-01, -1.5955e+00,  9.6479e+00,  7.8142e+00,  7.5847e+00,\n","         2.8834e+00,  3.0051e+00,  3.0180e+00,  5.5839e+00,  3.5273e+00,\n","         5.8731e+00,  7.0966e+00,  6.1974e+00,  2.1776e+00, -2.6488e-01,\n","         5.5760e+00,  8.0609e-01, -3.8005e-01,  1.2671e+00,  1.6228e+00,\n","         1.0556e+00,  5.9786e-01,  1.4458e+00, -5.5217e-01,  3.1686e+00,\n","         1.0026e+00, -1.1536e+00,  4.3645e+00,  8.2145e+00,  6.6015e+00,\n","         6.8358e+00,  1.7215e+00,  1.9038e+00, -1.9974e-01,  1.6893e+00,\n","         4.8216e+00,  5.6852e+00,  1.0464e+01,  1.5022e+01,  1.1129e+01,\n","         8.5484e+00,  1.1497e+01,  2.5779e+00,  3.6245e+00,  2.1349e+00,\n","         2.2959e+00,  1.4836e+00,  3.6168e+00, -6.4479e-02,  6.3409e+00,\n","         1.2028e+01,  3.6324e+00,  4.4857e+00,  3.9932e+00,  5.2923e+00,\n","         1.4355e-01,  2.6503e+00,  4.0086e+00,  3.9362e+00,  1.1420e+01,\n","         4.8062e+00,  1.7753e+00,  2.5963e+00,  6.9626e+00,  3.0403e+00,\n","         1.8695e+00,  1.3835e+00,  5.6297e+00, -3.0802e-01,  2.4820e+00,\n","        -1.7965e+00,  1.6015e+00,  2.2229e+00,  2.6527e+00, -1.4408e-01,\n","         1.0988e+00,  2.9356e+00, -2.4229e-01, -6.9108e-01, -7.9274e-01,\n","        -3.5151e+00, -2.8469e+00, -2.1138e+00, -2.0379e+00, -3.0407e+00,\n","        -3.9150e+00, -1.4829e+00, -2.6767e+00, -3.1710e+00, -2.9756e+00,\n","        -5.4036e-01, -2.0961e+00, -2.4282e+00, -1.7604e-01, -9.7277e-01,\n","        -4.7480e+00, -2.6363e+00, -9.4011e-01, -2.5570e+00, -3.7428e+00,\n","        -3.3482e+00, -2.5660e+00, -3.5957e+00, -2.8149e+00, -6.0690e-01,\n","        -2.4902e+00, -1.6169e+00, -8.8455e-01, -2.6267e+00, -3.3266e-01,\n","         3.0067e+00,  6.4583e+00,  7.8289e+00,  2.5335e+00,  1.5033e+00,\n","         1.5838e+00,  1.5846e+00,  1.4470e-01,  1.4442e+00,  1.2186e+00,\n","        -6.1507e-01,  3.8075e+00,  2.0746e+00, -1.2284e+00, -2.2567e+00,\n","         1.3234e+00,  5.7696e-01,  5.0180e-01,  5.0764e+00, -1.8332e-01,\n","         1.3564e+00, -2.4808e+00, -5.5934e-01,  1.6323e+00, -4.5652e-01,\n","         7.3214e+00,  3.3508e+00,  3.2359e+00,  3.6110e+00,  2.0883e+00,\n","        -2.1926e+00,  3.5784e+00,  1.0794e+00,  6.1011e-01, -1.0500e+00,\n","         8.9606e-01,  1.5123e-01,  1.2381e-01,  1.7613e+00, -6.4431e-01,\n","         1.1151e+00,  2.5225e+00,  1.9749e+00,  3.0662e+00,  2.8616e-01,\n","         5.2437e-02, -3.5607e+00,  2.9782e+00,  8.6055e-01,  5.1320e-01,\n","         3.4885e+00,  2.7851e-01,  1.4808e+00,  2.0800e+00,  3.1724e+00,\n","        -3.8745e+00, -4.9733e+00,  1.0157e+00,  1.4242e+00,  8.9270e-01,\n","        -1.7935e+00,  1.2723e+00, -2.2731e+00, -4.6565e+00, -9.6373e-02,\n","        -2.7754e-01, -4.9330e+00, -3.1597e+00,  9.0278e-01, -2.9004e+00,\n","        -1.0686e+00, -1.0255e+00, -8.3957e-01, -4.0400e+00, -1.7487e+00,\n","         8.3527e-02, -2.7471e+00, -9.1109e-01, -2.9025e-01,  8.9640e-01,\n","        -9.8466e-01, -3.6360e-02,  2.7735e+00,  3.4521e+00, -1.7855e+00,\n","        -1.6542e+00, -1.3879e+00,  3.7011e-01, -7.8917e-01, -9.8202e-02,\n","         5.7692e-01, -3.3723e-01,  1.8720e+00, -3.1413e+00, -3.4503e+00,\n","         8.0589e-01,  3.2697e-01,  2.3245e+00,  3.2783e+00,  2.0218e+00,\n","        -2.3803e+00,  9.7182e-03,  3.0292e-01,  1.0473e-01, -1.5844e+00,\n","         1.1383e+00, -1.3865e+00,  5.0617e-01, -2.9815e+00,  3.1816e+00,\n","         1.9252e+00,  1.1544e-01,  1.3847e+00, -1.2060e+00,  6.0810e-01,\n","        -1.2453e-01, -1.2491e+00,  3.9046e-01, -2.2055e+00,  9.9613e-01,\n","         4.4728e+00,  6.6272e-02,  3.3628e-01, -3.0910e-01, -1.9594e+00,\n","        -2.6097e-03,  1.9066e+00,  4.5661e-01,  5.4559e-01, -1.1660e+00,\n","         2.0348e+00,  5.3065e-01,  2.6528e+00,  2.5399e+00, -9.7215e-01,\n","         9.5864e-01, -1.3102e+00, -2.2024e+00, -3.4129e+00,  4.2549e+00,\n","        -8.3678e-01,  5.3707e-01,  3.2663e+00,  1.5515e+00, -1.2922e-01,\n","        -8.2356e-01,  5.5772e-01,  3.1631e-02, -1.3474e-01, -4.4561e-01,\n","        -6.3868e-01,  4.9981e-01, -8.1728e-01,  1.2743e-01, -1.8682e-02,\n","         9.3660e-03, -1.3573e-01,  8.3411e-01,  1.3148e+00,  1.0175e+00,\n","        -1.2564e+00,  1.5449e+00, -2.8365e-01, -4.1081e-01,  1.1536e+00,\n","         1.2160e+00, -5.0720e-01, -4.7460e-01, -2.2764e+00,  7.4996e-01,\n","        -2.6487e+00,  1.0633e+00, -1.7698e+00, -1.0776e+00, -7.3475e-01,\n","        -3.7660e-02, -1.9185e+00,  1.5138e+00,  1.7871e+00, -1.4723e+00,\n","        -9.6608e-01,  1.3113e-01,  3.2824e-02,  5.1930e-01, -8.3700e-01,\n","         2.1209e+00, -7.7029e-01, -2.4917e+00,  3.9311e-01, -8.2589e-01,\n","        -1.2934e+00, -4.2177e-02,  3.0053e+00,  1.9303e+00,  3.7649e-01,\n","         1.2310e+00, -1.9245e+00, -2.3942e-01,  3.9721e-01,  7.5824e-01,\n","         8.8300e-01, -1.1457e+00, -4.8210e-01, -1.7355e+00,  5.9856e-01,\n","        -2.2166e+00, -7.9912e-01,  3.7934e+00, -1.8692e+00,  3.6944e+00,\n","        -2.0836e+00,  8.4509e-02,  6.3985e-02,  6.0587e-01,  1.7179e+00,\n","         2.1375e+00, -4.8100e-02, -4.4287e+00, -5.5610e-01, -2.4003e+00,\n","        -3.0403e+00, -5.0421e-01,  2.1033e+00, -1.1482e+00, -1.3142e+00,\n","        -3.2275e+00,  1.4362e+00,  1.4927e-02,  6.4230e-03,  1.0523e+00,\n","         2.1179e+00, -8.7628e-01, -1.4112e+00, -1.5355e+00, -1.8525e+00,\n","        -5.7590e-01, -8.9818e-02,  1.0172e+00,  2.4756e+00, -1.8484e+00,\n","        -8.5055e-01, -6.8809e-01, -2.0868e-01,  7.5586e-01,  2.8956e+00,\n","        -2.2108e-01,  8.9520e-01,  3.1637e-01,  8.1690e-01,  6.7710e-01,\n","        -1.2364e-01, -2.3415e+00, -2.6306e+00,  3.4928e-01,  1.5489e+00,\n","        -4.1941e-01, -9.2284e-01,  9.1759e-01, -1.7461e+00,  1.3953e+00,\n","         2.8719e-01, -1.7282e+00,  5.0787e-01, -5.6566e-02, -3.8125e-01,\n","        -1.6108e+00,  3.0051e+00,  9.2698e-01, -8.2586e-01, -1.7922e+00,\n","        -3.0736e-01,  2.8025e-01, -1.9918e-01, -3.2624e-01, -1.6254e+00,\n","        -1.7217e+00,  1.4176e-01, -1.2882e+00, -1.0554e+00, -1.7673e+00,\n","         1.4972e-01,  5.3966e-01, -2.4115e+00,  3.1993e-01,  1.1110e+00,\n","         1.6402e+00, -2.2792e-01, -1.7062e+00, -5.2648e-01, -1.4641e+00,\n","         1.2677e+00,  2.8816e+00,  1.6108e+00, -2.5040e-01, -1.6037e+00,\n","         2.8917e-01, -1.1869e-01, -9.6835e-01, -1.8312e+00, -7.7066e-01,\n","         4.0867e-01,  4.8176e-01, -9.3827e-01,  6.0190e-01, -6.0401e-01,\n","        -6.5680e-01,  7.3458e-02,  3.1311e+00, -1.3530e+00, -7.1532e-01,\n","         1.2747e-01,  1.6126e+00, -1.1234e+00, -3.1548e-01, -1.7391e+00,\n","        -9.4634e-01,  1.0325e+00, -1.6125e+00, -9.6771e-01, -2.0451e+00,\n","        -8.0239e-01, -1.7056e+00,  8.3192e-01,  2.6702e+00, -1.1043e+00,\n","        -2.7450e-01, -1.2874e+00, -5.5403e-01,  9.7570e-01, -2.3876e+00,\n","         9.6986e-01, -2.1340e+00,  6.9162e-01, -1.4413e+00,  3.0597e-01,\n","        -1.5362e-01, -1.7704e+00,  1.7637e-01, -3.7636e+00, -5.5058e-01,\n","        -1.3961e-01,  1.0107e+00,  1.1486e+00,  1.0683e-01,  9.2261e-01,\n","         1.6997e-01,  2.9845e+00, -8.9600e-01, -4.0137e-01, -1.2877e+00,\n","         1.6305e+00,  1.5694e+00, -2.9471e+00,  4.9673e-01,  9.6277e-01,\n","        -5.0779e-01, -7.5207e-01, -1.5327e+00, -1.2753e+00, -7.0029e-01,\n","        -1.5427e+00, -1.7816e+00, -1.4085e-01,  1.6677e+00, -6.2805e-01,\n","         8.8111e-01,  1.8114e+00, -2.3170e+00, -4.8490e-02,  1.9054e+00,\n","         2.9645e+00,  1.0809e-01, -7.9349e-01,  2.5338e+00, -2.5340e+00,\n","         2.0317e-01,  5.7518e-01, -1.5134e+00, -4.2615e-01, -4.5054e-01,\n","        -8.8908e-01, -1.1672e+00,  6.6424e-01, -1.9194e+00, -6.0876e-01,\n","        -1.6464e+00,  9.5945e-01, -1.1004e+00, -5.8567e-01,  1.3900e+00,\n","         1.9603e-01, -1.7989e+00,  2.6827e+00,  4.5418e-01, -2.0131e+00,\n","        -1.4884e+00, -1.9153e+00, -5.3485e-01,  1.2981e+00, -1.6415e+00,\n","        -4.2884e-01,  5.6309e-01, -2.5833e+00,  6.7246e-01, -1.9165e+00,\n","        -1.9950e-01,  3.2181e-01, -1.0530e+00, -2.7198e+00, -2.3024e+00,\n","         1.9348e-01,  1.1623e-01,  1.8300e+00,  7.3302e-01,  1.0202e-01,\n","        -1.7705e+00,  1.7301e+00,  1.3856e+00,  3.1687e-01,  1.6640e+00,\n","        -2.7381e-01, -1.1863e+00,  1.1248e-01,  7.5356e-01, -1.4489e+00,\n","        -6.1184e-01,  3.7065e+00,  2.4525e-01,  1.9059e+00, -2.3370e+00,\n","        -1.2220e+00,  2.9274e+00, -1.9651e+00,  2.0299e+00,  4.4535e+00,\n","        -4.2486e-01,  3.2213e-01, -2.7372e+00,  2.6230e+00,  1.7232e+00,\n","        -1.8575e-01,  4.0165e-01, -2.5993e-01,  5.4951e-01, -1.1419e+00,\n","         2.1636e-01, -1.2100e+00, -3.5066e-01,  7.1617e-01, -1.1586e+00,\n","        -4.4105e-01, -1.0779e+00,  8.4869e-01, -4.2089e-01,  1.6454e+00,\n","        -4.0768e-01,  5.6872e-01,  2.5306e+00, -1.4206e+00,  1.8463e+00,\n","        -2.8954e+00, -8.0796e-01,  3.5169e+00,  1.0733e-01, -2.4912e+00,\n","         1.9501e+00, -1.7815e-01,  1.4052e+00, -9.9232e-01,  5.0284e-01,\n","        -1.7906e+00, -2.1315e+00, -9.6175e-01, -1.3111e+00, -4.7985e-01,\n","         4.0266e+00, -1.7616e-01,  1.0097e+00, -2.0628e-01, -2.5758e+00,\n","         1.7431e+00,  1.4820e+00, -1.1712e+00,  4.4352e-01,  2.7787e+00,\n","        -6.2947e-02, -1.0544e+00, -1.1036e+00,  1.0283e-01, -1.4615e+00,\n","         5.9688e-01, -2.8820e+00, -5.0279e-01,  8.7879e-01,  1.9169e+00,\n","         2.7618e-01,  2.9394e+00,  1.4490e+00,  5.0774e-01, -9.2605e-01,\n","        -7.1316e-02,  1.4216e+00, -1.7176e+00,  5.8615e-01, -1.1495e+00,\n","        -6.5585e-01,  1.8691e+00,  1.1023e+00,  2.1884e-01, -1.5120e+00,\n","         2.6911e-01, -6.0312e-01, -6.4153e-01,  1.3452e+00,  1.8411e+00,\n","        -6.5902e-02, -1.3929e+00, -1.8731e+00,  5.5448e-02,  3.5932e-01,\n","         5.6795e-01,  2.0173e+00,  3.7195e+00,  4.6933e-01, -7.2306e-01,\n","         8.3838e-02, -1.2997e+00, -2.0844e+00, -1.4839e+00, -1.6427e+00,\n","        -2.1517e-01, -1.1075e-01, -7.9383e-01, -8.2021e-01, -7.6609e-01,\n","        -1.1327e+00, -3.3431e-01,  4.7993e-01,  6.0664e-01, -5.7334e-01,\n","        -1.3184e+00, -1.1400e+00,  4.0159e-01, -2.4404e+00, -3.4461e+00,\n","         1.0840e+00,  2.7931e+00,  3.3868e-02, -1.5686e-01,  1.5065e+00,\n","        -5.9766e-01,  1.3963e+00,  1.2931e+00, -2.5687e+00, -2.0257e+00,\n","        -2.5593e+00, -6.3507e-01, -4.1855e+00, -1.0460e+00, -2.0383e-01,\n","         5.3520e-01, -7.6212e-02, -2.6302e-02, -9.1613e-01, -1.8891e+00,\n","        -1.7606e+00, -1.8577e-01, -8.0700e-01,  1.2513e+00, -8.3332e-03,\n","         5.1612e-01, -1.6129e+00,  3.2402e+00, -4.1609e-01,  9.6722e-01,\n","        -1.5514e+00, -2.4579e+00,  1.9270e-01, -1.4718e+00,  1.0546e-01,\n","        -5.8398e-01,  3.7532e-01,  2.9144e+00, -1.5144e+00, -4.0753e-01,\n","         7.4232e-01,  8.5648e-02, -2.5450e+00, -9.0387e-01,  2.6671e-01,\n","         1.3565e-02, -1.4115e-01, -2.8926e+00, -1.0020e+00, -2.4816e+00,\n","        -2.0267e+00, -7.1215e-01, -1.0165e+00, -2.5323e+00,  1.4648e+00,\n","        -2.1213e+00, -3.4827e+00, -6.2844e-01, -4.6919e+00, -1.9619e+00,\n","        -4.6035e-01,  1.2233e+00,  1.2137e+00,  1.5146e+00,  3.8147e-01,\n","        -1.4031e+00, -3.2279e+00, -1.3975e+00,  1.2478e+00, -2.2744e+00,\n","        -4.1773e+00, -1.3000e+00, -1.4723e+00,  1.6037e+00,  9.6354e-01,\n","        -1.2727e+00,  5.2836e-01, -4.3828e+00, -1.1360e+00, -1.7029e+00,\n","        -1.2807e+00, -8.0139e-01, -1.1293e+00,  3.5076e-01, -1.9611e+00,\n","        -2.1601e+00,  1.9285e-01, -1.0674e+00, -1.6967e+00, -3.2991e+00,\n","        -1.9158e+00,  9.5100e-02, -3.8192e+00, -3.2675e-03, -3.9538e-01,\n","         5.1634e-01,  8.0877e-01, -1.3149e-01, -3.3468e+00,  1.5624e+00,\n","         2.0383e+00, -1.0900e+00,  1.2827e+00, -1.5014e+00,  1.4722e+00,\n","        -1.4778e+00,  5.4960e-01,  5.4007e-01, -2.7867e+00, -3.8981e-01,\n","        -1.5041e+00, -3.4021e+00,  1.1703e+00, -2.3567e+00, -2.3079e+00,\n","        -1.5549e+00, -9.9510e-01, -1.5372e+00, -3.9012e+00, -3.3943e+00,\n","        -6.4585e-01, -3.2286e-01, -3.0958e+00,  4.1677e-01,  2.6843e+00])\n","tensor([7.8043e-07, 4.9593e-08, 2.1538e-08, 1.0254e-08, 7.2927e-08, 2.4724e-07,\n","        2.9504e-07, 2.6027e-06, 2.0490e-05, 6.5588e-07, 1.9251e-08, 4.1823e-08,\n","        1.1776e-08, 4.4539e-08, 1.6690e-07, 1.7511e-08, 3.5487e-08, 1.0741e-06,\n","        3.0756e-07, 3.7120e-08, 3.8044e-08, 4.0394e-07, 1.4399e-07, 1.1422e-06,\n","        1.0613e-07, 1.5318e-07, 1.0969e-07, 3.8899e-07, 1.7369e-07, 2.8956e-06,\n","        1.8564e-08, 2.2327e-07, 1.3335e-07, 7.1267e-09, 9.7144e-09, 1.7839e-08,\n","        4.0093e-08, 2.0693e-08, 1.0325e-07, 3.1048e-08, 1.4466e-07, 3.7499e-08,\n","        7.8838e-09, 2.6546e-08, 1.6722e-07, 1.5646e-08, 4.0609e-07, 1.2009e-07,\n","        3.8612e-08, 2.8345e-07, 4.4641e-07, 8.4091e-08, 2.8816e-07, 2.6459e-08,\n","        3.6233e-08, 3.2654e-08, 1.3115e-07, 2.0615e-08, 5.3690e-08, 1.3373e-07,\n","        3.1066e-07, 4.5066e-08, 1.2624e-07, 1.7139e-08, 5.5488e-08, 1.6581e-08,\n","        3.9277e-08, 4.0109e-08, 1.2083e-07, 8.0287e-09, 2.4112e-08, 1.3889e-07,\n","        8.5556e-08, 7.6754e-08, 2.0446e-08, 2.1802e-07, 1.1049e-07, 1.2768e-07,\n","        9.7488e-07, 4.7555e-07, 2.7502e-07, 2.2952e-06, 1.6903e-07, 1.2439e-07,\n","        5.5393e-07, 7.0092e-08, 1.1168e-07, 5.1800e-08, 3.7728e-08, 8.5991e-06,\n","        5.6012e-08, 1.7471e-08, 3.5243e-09, 6.5867e-08, 2.5543e-08, 7.7798e-09,\n","        3.8250e-08, 7.2803e-09, 1.9717e-09, 2.0858e-07, 8.9554e-08, 5.8518e-09,\n","        1.5413e-07, 1.4093e-08, 3.3139e-04, 1.4126e-07, 1.8189e-06, 6.5465e-09,\n","        3.7296e-08, 1.4178e-08, 7.3172e-08, 1.7793e-08, 6.7414e-08, 9.4450e-08,\n","        1.0218e-07, 1.4565e-07, 5.5186e-09, 1.7814e-08, 9.3621e-08, 6.7325e-08,\n","        8.4641e-09, 9.9879e-08, 1.0384e-07, 5.6833e-08, 7.7316e-08, 9.9827e-09,\n","        1.9807e-07, 5.5202e-07, 2.1102e-08, 4.8423e-07, 6.2812e-08, 5.9166e-08,\n","        6.5204e-07, 8.9753e-10, 2.2236e-07, 4.5837e-08, 1.7138e-08, 5.1893e-09,\n","        1.2984e-08, 9.2498e-09, 9.5136e-09, 6.2976e-09, 9.4746e-09, 8.5478e-08,\n","        1.1946e-07, 2.3683e-07, 3.4206e-07, 1.3830e-08, 5.4681e-09, 9.7285e-08,\n","        1.5217e-08, 2.0732e-05, 8.1979e-05, 2.0603e-05, 1.6311e-04, 1.0023e-07,\n","        3.0542e-07, 6.4786e-05, 9.2050e-07, 1.3232e-07, 1.6876e-06, 5.6755e-08,\n","        5.4187e-08, 3.6698e-07, 3.3049e-08, 2.7096e-08, 1.6844e-07, 4.0289e-08,\n","        1.0906e-06, 3.3465e-05, 3.7269e-06, 1.1721e-07, 1.8710e-08, 6.3978e-07,\n","        1.9047e-04, 9.8863e-07, 3.4834e-08, 3.0526e-06, 3.4452e-08, 2.3595e-06,\n","        5.2231e-07, 6.7551e-08, 8.0910e-07, 6.7640e-08, 1.3828e-06, 9.2992e-06,\n","        5.8471e-06, 8.1721e-08, 1.5731e-06, 4.4447e-08, 4.6923e-07, 2.5338e-08,\n","        1.3740e-05, 6.9780e-06, 2.3822e-07, 6.6805e-07, 1.6084e-08, 8.7301e-08,\n","        2.8393e-08, 1.1587e-05, 6.9662e-07, 5.3522e-07, 7.5073e-07, 2.3410e-04,\n","        8.3199e-07, 7.2929e-07, 1.6894e-07, 2.2972e-05, 3.2511e-06, 2.4999e-07,\n","        7.1911e-08, 4.7902e-07, 4.0721e-06, 7.4738e-07, 2.6935e-07, 1.0969e-06,\n","        3.1971e-06, 1.6973e-07, 2.4195e-07, 2.0101e-07, 6.3204e-07, 5.2653e-08,\n","        4.0213e-03, 6.4268e-04, 5.1087e-04, 4.6408e-06, 5.2413e-06, 5.3093e-06,\n","        6.9082e-05, 8.8350e-06, 9.2254e-05, 3.1357e-04, 1.2759e-04, 2.2912e-06,\n","        1.9920e-07, 6.8541e-05, 5.8131e-07, 1.7753e-07, 9.2177e-07, 1.3155e-06,\n","        7.4602e-07, 4.7204e-07, 1.1021e-06, 1.4946e-07, 6.1723e-06, 7.0754e-07,\n","        8.1905e-08, 2.0409e-05, 9.5904e-04, 1.9112e-04, 2.4160e-04, 1.4520e-06,\n","        1.7423e-06, 2.1261e-07, 1.4060e-06, 3.2234e-05, 7.6453e-05, 9.0907e-03,\n","        8.6800e-01, 1.7686e-02, 1.3392e-03, 2.5546e-02, 3.4188e-06, 9.7375e-06,\n","        2.1954e-06, 2.5788e-06, 1.1446e-06, 9.6628e-06, 2.4340e-07, 1.4728e-04,\n","        4.3434e-02, 9.8145e-06, 2.3039e-05, 1.4079e-05, 5.1611e-05, 2.9969e-07,\n","        3.6756e-06, 1.4297e-05, 1.3299e-05, 2.3647e-02, 3.1743e-05, 1.5323e-06,\n","        3.4823e-06, 2.7425e-04, 5.4287e-06, 1.6837e-06, 1.0355e-06, 7.2321e-05,\n","        1.9079e-07, 3.1063e-06, 4.3065e-08, 1.2878e-06, 2.3974e-06, 3.6844e-06,\n","        2.2478e-07, 7.7896e-07, 4.8891e-06, 2.0375e-07, 1.3008e-07, 1.1750e-07,\n","        7.7225e-09, 1.5063e-08, 3.1355e-08, 3.3827e-08, 1.2411e-08, 5.1769e-09,\n","        5.8928e-08, 1.7859e-08, 1.0894e-08, 1.3245e-08, 1.5124e-07, 3.1914e-08,\n","        2.2898e-08, 2.1771e-07, 9.8144e-08, 2.2506e-09, 1.8595e-08, 1.0140e-07,\n","        2.0130e-08, 6.1495e-09, 9.1244e-09, 1.9949e-08, 7.1244e-09, 1.5553e-08,\n","        1.4150e-07, 2.1521e-08, 5.1535e-08, 1.0719e-07, 1.8774e-08, 1.8615e-07,\n","        5.2494e-06, 1.6562e-04, 6.5221e-04, 3.2704e-06, 1.1674e-06, 1.2652e-06,\n","        1.2662e-06, 3.0003e-07, 1.1004e-06, 8.7816e-07, 1.4035e-07, 1.1692e-05,\n","        2.0669e-06, 7.6003e-08, 2.7180e-08, 9.7519e-07, 4.6228e-07, 4.2880e-07,\n","        4.1589e-05, 2.1613e-07, 1.0078e-06, 2.1724e-08, 1.4839e-07, 1.3281e-06,\n","        1.6446e-07, 3.9263e-04, 7.4055e-06, 6.6021e-06, 9.6062e-06, 2.0954e-06,\n","        2.8981e-08, 9.2987e-06, 7.6401e-07, 4.7786e-07, 9.0853e-08, 6.3604e-07,\n","        3.0200e-07, 2.9383e-07, 1.5110e-06, 1.3630e-07, 7.9176e-07, 3.2346e-06,\n","        1.8707e-06, 5.5717e-06, 3.4563e-07, 2.7359e-07, 7.3778e-09, 5.1021e-06,\n","        6.1385e-07, 4.3372e-07, 8.4992e-06, 3.4299e-07, 1.1414e-06, 2.0780e-06,\n","        6.1955e-06, 5.3908e-09, 1.7966e-09, 7.1686e-07, 1.0786e-06, 6.3391e-07,\n","        4.3194e-08, 9.2662e-07, 2.6738e-08, 2.4663e-09, 2.3576e-07, 1.9670e-07,\n","        1.8706e-09, 1.1018e-08, 6.4033e-07, 1.4279e-08, 8.9171e-08, 9.3098e-08,\n","        1.1213e-07, 4.5684e-09, 4.5175e-08, 2.8223e-07, 1.6644e-08, 1.0439e-07,\n","        1.9421e-07, 6.3626e-07, 9.6984e-08, 2.5035e-07, 4.1575e-06, 8.1952e-06,\n","        4.3541e-08, 4.9651e-08, 6.4800e-08, 3.7590e-07, 1.1792e-07, 2.3533e-07,\n","        4.6226e-07, 1.8530e-07, 1.6878e-06, 1.1223e-08, 8.2393e-09, 5.8120e-07,\n","        3.6002e-07, 2.6537e-06, 6.8878e-06, 1.9605e-06, 2.4020e-08, 2.6215e-07,\n","        3.5147e-07, 2.8828e-07, 5.3242e-08, 8.1040e-07, 6.4889e-08, 4.3068e-07,\n","        1.3166e-08, 6.2531e-06, 1.7801e-06, 2.9138e-07, 1.0368e-06, 7.7724e-08,\n","        4.7690e-07, 2.2922e-07, 7.4446e-08, 3.8362e-07, 2.8607e-08, 7.0298e-07,\n","        2.2743e-05, 2.7740e-07, 3.6339e-07, 1.9059e-07, 3.6592e-08, 2.5894e-07,\n","        1.7472e-06, 4.0986e-07, 4.4800e-07, 8.0902e-08, 1.9862e-06, 4.4135e-07,\n","        3.6849e-06, 3.2917e-06, 9.8205e-08, 6.7711e-07, 7.0034e-08, 2.8696e-08,\n","        8.5533e-09, 1.8290e-05, 1.1244e-07, 4.4420e-07, 6.8055e-06, 1.2250e-06,\n","        2.2814e-07, 1.1394e-07, 4.5347e-07, 2.6796e-07, 2.2689e-07, 1.6627e-07,\n","        1.3707e-07, 4.2795e-07, 1.1465e-07, 2.9490e-07, 2.5481e-07, 2.6206e-07,\n","        2.2666e-07, 5.9783e-07, 9.6677e-07, 7.1815e-07, 7.3905e-08, 1.2170e-06,\n","        1.9550e-07, 1.7215e-07, 8.2284e-07, 8.7583e-07, 1.5634e-07, 1.6152e-07,\n","        2.6651e-08, 5.4958e-07, 1.8365e-08, 7.5181e-07, 4.4228e-08, 8.8379e-08,\n","        1.2452e-07, 2.5002e-07, 3.8118e-08, 1.1796e-06, 1.5504e-06, 5.9552e-08,\n","        9.8802e-08, 2.9599e-07, 2.6828e-07, 4.3637e-07, 1.1241e-07, 2.1649e-06,\n","        1.2017e-07, 2.1488e-08, 3.8464e-07, 1.1367e-07, 7.1218e-08, 2.4889e-07,\n","        5.2420e-06, 1.7892e-06, 3.7830e-07, 8.8910e-07, 3.7890e-08, 2.0434e-07,\n","        3.8622e-07, 5.5415e-07, 6.2779e-07, 8.2560e-08, 1.6031e-07, 4.5773e-08,\n","        4.7237e-07, 2.8292e-08, 1.1676e-07, 1.1529e-05, 4.0046e-08, 1.0442e-05,\n","        3.2317e-08, 2.8251e-07, 2.7677e-07, 4.7583e-07, 1.4468e-06, 2.2011e-06,\n","        2.4742e-07, 3.0971e-09, 1.4887e-07, 2.3545e-08, 1.2415e-08, 1.5680e-07,\n","        2.1271e-06, 8.2348e-08, 6.9759e-08, 1.0296e-08, 1.0916e-06, 2.6352e-07,\n","        2.6129e-07, 7.4359e-07, 2.1583e-06, 1.0809e-07, 6.3307e-08, 5.5905e-08,\n","        4.0718e-08, 1.4595e-07, 2.3731e-07, 7.1794e-07, 3.0865e-06, 4.0885e-08,\n","        1.1090e-07, 1.3047e-07, 2.1072e-07, 5.5284e-07, 4.6974e-06, 2.0812e-07,\n","        6.3549e-07, 3.5623e-07, 5.8763e-07, 5.1096e-07, 2.2942e-07, 2.4970e-08,\n","        1.8701e-08, 3.6815e-07, 1.2218e-06, 1.7068e-07, 1.0317e-07, 6.4988e-07,\n","        4.5290e-08, 1.0479e-06, 3.4598e-07, 4.6108e-08, 4.3141e-07, 2.4534e-07,\n","        1.7732e-07, 5.1851e-08, 5.2411e-06, 6.5601e-07, 1.1367e-07, 4.3251e-08,\n","        1.9092e-07, 3.4359e-07, 2.1273e-07, 1.8735e-07, 5.1101e-08, 4.6409e-08,\n","        2.9915e-07, 7.1593e-08, 9.0363e-08, 4.4343e-08, 3.0155e-07, 4.4535e-07,\n","        2.3283e-08, 3.5750e-07, 7.8853e-07, 1.3386e-06, 2.0670e-07, 4.7135e-08,\n","        1.5335e-07, 6.0047e-08, 9.2231e-07, 4.6322e-06, 1.2999e-06, 2.0211e-07,\n","        5.2224e-08, 3.4667e-07, 2.3056e-07, 9.8579e-08, 4.1596e-08, 1.2013e-07,\n","        3.9067e-07, 4.2030e-07, 1.0159e-07, 4.7395e-07, 1.4191e-07, 1.3461e-07,\n","        2.7940e-07, 5.9451e-06, 6.7099e-08, 1.2696e-07, 2.9491e-07, 1.3022e-06,\n","        8.4417e-08, 1.8937e-07, 4.5608e-08, 1.0077e-07, 7.2905e-07, 5.1763e-08,\n","        9.8642e-08, 3.3587e-08, 1.1637e-07, 4.7165e-08, 5.9653e-07, 3.7497e-06,\n","        8.6049e-08, 1.9730e-07, 7.1649e-08, 1.4918e-07, 6.8876e-07, 2.3845e-08,\n","        6.8475e-07, 3.0729e-08, 5.1844e-07, 6.1429e-08, 3.5254e-07, 2.2265e-07,\n","        4.4203e-08, 3.0969e-07, 6.0232e-09, 1.4970e-07, 2.2579e-07, 7.1328e-07,\n","        8.1879e-07, 2.8889e-07, 6.5316e-07, 3.0771e-07, 5.1342e-06, 1.0597e-07,\n","        1.7379e-07, 7.1628e-08, 1.3257e-06, 1.2471e-06, 1.3627e-08, 4.2664e-07,\n","        6.7991e-07, 1.5624e-07, 1.2238e-07, 5.6066e-08, 7.2525e-08, 1.2888e-07,\n","        5.5506e-08, 4.3712e-08, 2.2551e-07, 1.3760e-06, 1.3854e-07, 6.2660e-07,\n","        1.5885e-06, 2.5591e-08, 2.4733e-07, 1.7452e-06, 5.0325e-06, 2.8925e-07,\n","        1.1741e-07, 3.2713e-06, 2.0599e-08, 3.1810e-07, 4.6145e-07, 5.7157e-08,\n","        1.6953e-07, 1.6545e-07, 1.0671e-07, 8.0803e-08, 5.0444e-07, 3.8083e-08,\n","        1.4124e-07, 5.0040e-08, 6.7766e-07, 8.6387e-08, 1.4454e-07, 1.0423e-06,\n","        3.1584e-07, 4.2961e-08, 3.7967e-06, 4.0886e-07, 3.4679e-08, 5.8605e-08,\n","        3.8243e-08, 1.5207e-07, 9.5080e-07, 5.0286e-08, 1.6908e-07, 4.5591e-07,\n","        1.9608e-08, 5.0860e-07, 3.8195e-08, 2.1266e-07, 3.5817e-07, 9.0581e-08,\n","        1.7106e-08, 2.5966e-08, 3.1503e-07, 2.9161e-07, 1.6185e-06, 5.4035e-07,\n","        2.8750e-07, 4.4198e-08, 1.4646e-06, 1.0378e-06, 3.5640e-07, 1.3709e-06,\n","        1.9743e-07, 7.9270e-08, 2.9052e-07, 5.5156e-07, 6.0968e-08, 1.4080e-07,\n","        1.0569e-05, 3.3177e-07, 1.7460e-06, 2.5082e-08, 7.6496e-08, 4.8495e-06,\n","        3.6383e-08, 1.9766e-06, 2.2308e-05, 1.6975e-07, 3.5829e-07, 1.6810e-08,\n","        3.5767e-06, 1.4545e-06, 2.1561e-07, 3.8794e-07, 2.0019e-07, 4.4976e-07,\n","        8.2875e-08, 3.2232e-07, 7.7415e-08, 1.8283e-07, 5.3132e-07, 8.1500e-08,\n","        1.6703e-07, 8.8350e-08, 6.0661e-07, 1.7043e-07, 1.3457e-06, 1.7269e-07,\n","        4.5848e-07, 3.2612e-06, 6.2716e-08, 1.6451e-06, 1.4351e-08, 1.1573e-07,\n","        8.7441e-06, 2.8903e-07, 2.1499e-08, 1.8249e-06, 2.1725e-07, 1.0583e-06,\n","        9.6243e-08, 4.2925e-07, 4.3320e-08, 3.0805e-08, 9.9231e-08, 6.9972e-08,\n","        1.6067e-07, 1.4557e-05, 2.1768e-07, 7.1258e-07, 2.1122e-07, 1.9755e-08,\n","        1.4837e-06, 1.1428e-06, 8.0477e-08, 4.0453e-07, 4.1793e-06, 2.4378e-07,\n","        9.0447e-08, 8.6106e-08, 2.8773e-07, 6.0201e-08, 4.7158e-07, 1.4544e-08,\n","        1.5703e-07, 6.2515e-07, 1.7653e-06, 3.4220e-07, 4.9080e-06, 1.1057e-06,\n","        4.3136e-07, 1.0284e-07, 2.4175e-07, 1.0758e-06, 4.6602e-08, 4.6654e-07,\n","        8.2244e-08, 1.3474e-07, 1.6829e-06, 7.8174e-07, 3.2312e-07, 5.7234e-08,\n","        3.3979e-07, 1.4204e-07, 1.3668e-07, 9.9666e-07, 1.6365e-06, 2.4306e-07,\n","        6.4478e-08, 3.9889e-08, 2.7442e-07, 3.7186e-07, 4.5813e-07, 1.9519e-06,\n","        1.0707e-05, 4.1510e-07, 1.2598e-07, 2.8232e-07, 7.0776e-08, 3.2293e-08,\n","        5.8869e-08, 5.0226e-08, 2.0936e-07, 2.3240e-07, 1.1737e-07, 1.1432e-07,\n","        1.2068e-07, 8.3638e-08, 1.8584e-07, 4.1953e-07, 4.7620e-07, 1.4633e-07,\n","        6.9466e-08, 8.3028e-08, 3.8792e-07, 2.2618e-08, 8.2736e-09, 7.6754e-07,\n","        4.2401e-06, 2.6856e-07, 2.2193e-07, 1.1711e-06, 1.4281e-07, 1.0489e-06,\n","        9.4610e-07, 1.9895e-08, 3.4244e-08, 2.0083e-08, 1.3757e-07, 3.9499e-09,\n","        9.1217e-08, 2.1174e-07, 4.4337e-07, 2.4056e-07, 2.5288e-07, 1.0386e-07,\n","        3.9257e-08, 4.4638e-08, 2.1560e-07, 1.1584e-07, 9.0736e-07, 2.5746e-07,\n","        4.3499e-07, 5.1746e-08, 6.6303e-06, 1.7125e-07, 6.8295e-07, 5.5024e-08,\n","        2.2226e-08, 3.1479e-07, 5.9583e-08, 2.8849e-07, 1.4478e-07, 3.7786e-07,\n","        4.7867e-06, 5.7102e-08, 1.7272e-07, 5.4540e-07, 2.8283e-07, 2.0373e-08,\n","        1.0514e-07, 3.3897e-07, 2.6316e-07, 2.2544e-07, 1.4390e-08, 9.5312e-08,\n","        2.1706e-08, 3.4210e-08, 1.2736e-07, 9.3941e-08, 2.0634e-08, 1.1233e-06,\n","        3.1121e-08, 7.9765e-09, 1.3848e-07, 2.3806e-09, 3.6501e-08, 1.6383e-07,\n","        8.8229e-07, 8.7381e-07, 1.1807e-06, 3.8019e-07, 6.3823e-08, 1.0291e-08,\n","        6.4179e-08, 9.0419e-07, 2.6705e-08, 3.9825e-09, 7.0754e-08, 5.9553e-08,\n","        1.2906e-06, 6.8044e-07, 7.2714e-08, 4.4034e-07, 3.2427e-09, 8.3362e-08,\n","        4.7291e-08, 7.2133e-08, 1.1649e-07, 8.3924e-08, 3.6869e-07, 3.6528e-08,\n","        2.9937e-08, 3.1484e-07, 8.9280e-08, 4.7583e-08, 9.5843e-09, 3.8221e-08,\n","        2.8552e-07, 5.6973e-09, 2.5877e-07, 1.7483e-07, 4.3509e-07, 5.8288e-07,\n","        2.2763e-07, 9.1377e-09, 1.2385e-06, 1.9932e-06, 8.7287e-08, 9.3629e-07,\n","        5.7847e-08, 1.1316e-06, 5.9230e-08, 4.4980e-07, 4.4553e-07, 1.5998e-08,\n","        1.7581e-07, 5.7690e-08, 8.6464e-09, 8.3675e-07, 2.4593e-08, 2.5823e-08,\n","        5.4834e-08, 9.5976e-08, 5.5815e-08, 5.2490e-09, 8.7135e-09, 1.3609e-07,\n","        1.8798e-07, 1.1744e-08, 3.9385e-07, 3.8029e-06])\n"]}]},{"cell_type":"code","source":["# Download ImageNet labels\n","!wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_0keekz3YSkD","executionInfo":{"status":"ok","timestamp":1649273910879,"user_tz":240,"elapsed":366,"user":{"displayName":"Nancy Li","userId":"12562624317552008542"}},"outputId":"6069138a-7403-48ab-8548-ff11c4a92abc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-04-06 19:38:30--  https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 10472 (10K) [text/plain]\n","Saving to: ‘imagenet_classes.txt’\n","\n","imagenet_classes.tx 100%[===================>]  10.23K  --.-KB/s    in 0s      \n","\n","2022-04-06 19:38:30 (97.2 MB/s) - ‘imagenet_classes.txt’ saved [10472/10472]\n","\n"]}]},{"cell_type":"code","source":["# Read the categories\n","with open(\"imagenet_classes.txt\", \"r\") as f:\n","    categories = [s.strip() for s in f.readlines()]\n","# Show top categories per image\n","top5_prob, top5_catid = torch.topk(probabilities, 5)\n","for i in range(top5_prob.size(0)):\n","    print(categories[top5_catid[i]], top5_prob[i].item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fJk01voBYSg5","executionInfo":{"status":"ok","timestamp":1649273922154,"user_tz":240,"elapsed":205,"user":{"displayName":"Nancy Li","userId":"12562624317552008542"}},"outputId":"06e4889b-874c-437e-c323-ab253c75c8a4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Samoyed 0.8679969310760498\n","white wolf 0.04343400150537491\n","keeshond 0.025546222925186157\n","Arctic fox 0.023647291585803032\n","Pomeranian 0.01768600568175316\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"RyYcNFDQjj4i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Complete DenseNet 121 architecture**\n","\n","https://towardsdatascience.com/creating-densenet-121-with-tensorflow-edbc08a956d8"],"metadata":{"id":"5SBklpbnjxyR"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Dense\n","from tensorflow.keras.layers import AvgPool2D, GlobalAveragePooling2D, MaxPool2D\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import ReLU, concatenate\n","import tensorflow.keras.backend as K\n","# Creating Densenet121\n","def densenet(input_shape, n_classes, filters = 32):\n","    \n","    #batch norm + relu + conv\n","    def bn_rl_conv(x,filters,kernel=1,strides=1):\n","        \n","        x = BatchNormalization()(x)\n","        x = ReLU()(x)\n","        x = Conv2D(filters, kernel, strides=strides,padding = 'same')(x)\n","        return x\n","    \n","    def dense_block(x, repetition):\n","        \n","        for _ in range(repetition):\n","            y = bn_rl_conv(x, 4*filters)\n","            y = bn_rl_conv(y, filters, 3)\n","            x = concatenate([y,x])\n","        return x\n","        \n","    def transition_layer(x):\n","        \n","        x = bn_rl_conv(x, K.int_shape(x)[-1] //2 )\n","        x = AvgPool2D(2, strides = 2, padding = 'same')(x)\n","        return x\n","    \n","    input = Input (input_shape)\n","    x = Conv2D(64, 7, strides = 2, padding = 'same')(input)\n","    x = MaxPool2D(3, strides = 2, padding = 'same')(x)\n","    \n","    for repetition in [6,12,24,16]:\n","        \n","        d = dense_block(x, repetition)\n","        x = transition_layer(d)\n","    x = GlobalAveragePooling2D()(d)\n","    output = Dense(n_classes, activation = 'softmax')(x)\n","    \n","    model = Model(input, output)\n","    return model\n","input_shape = 224, 224, 3\n","n_classes = 3\n","model = densenet(input_shape,n_classes)\n","model.summary()"],"metadata":{"id":"8PqEB70VjkDh"},"execution_count":null,"outputs":[]}]}